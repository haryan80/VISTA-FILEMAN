{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f00bff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import paramiko\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46689961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import paramiko\n",
    "from datetime import datetime, timedelta\n",
    "from IPython.display import clear_output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Constants\n",
    "SERVER_NAME=\"\"\n",
    "DATABASE=\"\"\n",
    "UID=\"\"\n",
    "PWD=\"\"\n",
    "BATCH_SIZE=2000\n",
    "FILEMAN_IP=\"\"\n",
    "FILEMAN_USER=\"\"\n",
    "FILEMAN_PASSWORD=\"\"\n",
    "VISTA_USERNAME=\"\"\n",
    "VISTA_PASSWORD=\"\"\n",
    "FILEMAN_SETTING_FILE_PATH=\"fileman_labs_conditions2.xlsx\"\n",
    "\n",
    "def establish_connection():\n",
    "    \"\"\"Establish a connection to the SQL Server.\"\"\"\n",
    "    try:\n",
    "        conn = pyodbc.connect('DRIVER={ODBC Driver 18 for SQL Server};'\n",
    "                              f'SERVER={SERVER_NAME};'\n",
    "                              f'DATABASE={DATABASE}; UID={UID}; PWD={PWD};')\n",
    "        print(\"Connection successful!\")\n",
    "        return conn\n",
    "    except pyodbc.Error as e:\n",
    "        print(\"Connection error:\", e)\n",
    "        return None\n",
    "\n",
    "def get_max_value_from_db(conn):\n",
    "    \"\"\"Retrieve the maximum value from the NUMBER column in the LAB table.\"\"\"\n",
    "    sql_get = \"SELECT MAX([DATE REPORT COMPLETED]) FROM LAB;\"\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql_get)\n",
    "    max_value = cursor.fetchone()[0]\n",
    "    cursor.close()\n",
    "    return max_value.strftime(\"%m/%d/%Y@%H:%M\") if max_value is not None else '01/01/1900'\n",
    "\n",
    "def update_excel_with_max_value(file_path, max_value):\n",
    "    \"\"\"Update the Excel file with the maximum value retrieved from the database.\"\"\"\n",
    "    df = pd.read_excel(file_path, header=None)\n",
    "    df.iloc[4, 0] = max_value\n",
    "    return df\n",
    "\n",
    "def generate_fileman_string(df):\n",
    "    \"\"\"Generate a string for the FileMan search based on the updated Excel file.\"\"\"\n",
    "    return ''.join(str(row[0]) + '\\n' if not pd.isna(row[0]) else '\\x0d' for _, row in df.iterrows())\n",
    "\n",
    "def setup_ssh_connection(host, username, password, port=22):\n",
    "    \"\"\"Set up an SSH connection.\"\"\"\n",
    "    paramiko.util.log_to_file(\"patient_labs.log\")\n",
    "    ssh = paramiko.SSHClient()\n",
    "    ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "    ssh.connect(host, username=username, password=password, port=port)\n",
    "    return ssh\n",
    "\n",
    "def truncate_string(value, max_length):\n",
    "    \"\"\"Truncate string to the specified maximum length.\"\"\"\n",
    "    if isinstance(value, str) and len(value) > max_length:\n",
    "        return value[:max_length]\n",
    "    return value\n",
    "string_columns_max_length = {\n",
    "        \"SPECIMEN TYPE\": 100,\n",
    "        \"REQUESTING LOCATION\": 100,\n",
    "        \"REQUESTING LOC/DIV\": 100,\n",
    "        \"TEST_NAME\": 50,\n",
    "        \"TEST_RESULT\": 200\n",
    "    }\n",
    "            \n",
    "\n",
    "def extract_data():\n",
    "    \"\"\"Main function to extract data by connecting to the database and performing SSH operations.\"\"\"\n",
    "    conn = establish_connection()\n",
    "    if not conn:\n",
    "        return\n",
    "\n",
    "    max_value = get_max_value_from_db(conn)\n",
    "    conn.close()\n",
    "    global start_date\n",
    "    global end_date\n",
    "    print(f\"The maximum Date in the column DATE REPORT COMPLETED is: {max_value}\")\n",
    "    start_date=pd.to_datetime(max_value,format=\"%m/%d/%Y@%H:%M\")\n",
    "    print(f\"The start Date  is: {start_date}\")\n",
    "    end_date=pd.to_datetime(datetime.now()-timedelta(minutes=2))\n",
    "    print(f\"The end Date  is: {end_date}\")\n",
    "    \n",
    "    fileman_search = update_excel_with_max_value(FILEMAN_SETTING_FILE_PATH, max_value)\n",
    "    fileman = generate_fileman_string(fileman_search)\n",
    "    \n",
    "    steps = [\n",
    "        '\\x0d',\n",
    "        VISTA_USERNAME,\n",
    "        '\\x0d',\n",
    "        VISTA_PASSWORD,\n",
    "        '\\x0d',\n",
    "        '\\x0d',\n",
    "        'Search File Entries\\n',\n",
    "        fileman\n",
    "    ]\n",
    "\n",
    "    ssh = setup_ssh_connection(FILEMAN_IP, FILEMAN_USER, FILEMAN_PASSWORD)\n",
    "    channel = ssh.invoke_shell()\n",
    "\n",
    "    if os.path.exists('output_labs.txt'):\n",
    "        os.remove('output_labs.txt')\n",
    "    \n",
    "    \n",
    "    for step in steps[:-1]:\n",
    "        channel.send(step)\n",
    "        while not channel.recv_ready():\n",
    "            time.sleep(3)\n",
    "        out = channel.recv(9999)\n",
    "        print(out.decode('cp1256'))\n",
    "        if 'invalid signon attempts.' in out.decode('cp1256') or 'Device/IP address is locked in' in out.decode('cp1256') or 'Do you really want to halt? YES//' in out.decode('cp1256') or 'Not a valid ACCESS CODE' in out.decode('cp1256') :\n",
    "            print(f\"Sorry, invalid signon attempts, i will retry after 1 min\")\n",
    "            time.sleep(60)\n",
    "            main_function() \n",
    "    channel.send(steps[-1])\n",
    "    prev_output = \"\"\n",
    "    while True:\n",
    "        out = channel.recv(9999).decode('cp1256')\n",
    "        with open('output_labs.txt', 'a') as f:\n",
    "            f.write(out)\n",
    "        \n",
    "        combined_output = prev_output + out\n",
    "        prev_output = out\n",
    "\n",
    "        if \"MATCHES FOUND\" in combined_output or \"MATCH FOUND\" in combined_output:\n",
    "            ssh.close()\n",
    "            break\n",
    "\n",
    "    print(\"Data extraction ended.\")\n",
    "    \n",
    "#     ssh.close()\n",
    "\n",
    "def close_connection(conn):\n",
    "    \"\"\"Close the database connection.\"\"\"\n",
    "    if conn:\n",
    "        conn.close()\n",
    "        print(\"Connection closed.\")\n",
    "\n",
    "def parse_file(filename,conn):\n",
    "    \"\"\"Parse the file and insert data into the database.\"\"\"\n",
    "    batch_size =100000\n",
    "    total_number = 0\n",
    "    data_list = []\n",
    "    count = 0\n",
    "    num_lines = sum(1 for line in open(filename))\n",
    "    print(f\"Number of lines is : {num_lines}\")\n",
    "    pbar = tqdm(total=num_lines)\n",
    "    \n",
    "    columns = [\n",
    "        \"MRN\", \"DATE/TIME SPECIMEN TAKEN\", \"DATE REPORT COMPLETED\",\"SPECIMEN TYPE\", \"REQUESTING LOCATION\",\n",
    "        \"REQUESTING LOC/DIV\", \"TEST_NAME\",\"TEST_RESULT\"\n",
    "    ]\n",
    "    # List of specific labels to exclude\n",
    "    exclude_labels = [\"PARENT FILE\", \"LRDFN\", \"NAME\", \"REPORT ROUTING (LOCATION)\", \"REPORT ROUTING (PROVIDER)\",\"VERIFY PERSON\",\n",
    "                 \"ACCESSION\",\"METHOD OR SITE\",\"REQUESTING PERSON\",\"ACCESSIONING INSTITUTION\",\"UID\",\"COMMENT\",\"NEW PERSON CONVERSION\",\n",
    "                  \"ORDERED TEST\",\"RESP.INTERPRETATION\",\"DATE/TIME OF DEATH (c)\",\"NUMBER\",\"Approved By:\",\"SITE/SPECIMEN\",\"WARD\",\"LOCATION TYPE\",\n",
    "                   \"SAMPLE TYPE\",   \n",
    "                 \n",
    "                 \n",
    "                 ]\n",
    "    check=True\n",
    "    with open(filename) as file:\n",
    "\n",
    "        parsed_data = {}\n",
    "        for line in file:\n",
    "            pbar.update(1)\n",
    "            split_line = line.split(\" \" * 3)\n",
    "            for part in split_line: \n",
    "                if part.find(\": MRN IS <<<<>>>>\")!=-1:\n",
    "                   \n",
    "\n",
    "                    if data_list:\n",
    "                        insert_data_batch(conn, data_list, columns,batch_size,start_date,end_date)\n",
    "                        parsed_data = {}\n",
    "                        data_list.clear()\n",
    "                    parsed_data[\"MRN\"] = part[17:-1]\n",
    "                    \n",
    "\n",
    "                else:\n",
    "                    if \": \" in part:\n",
    "                        parts = part.split(\": \")\n",
    "                        key = parts[0].strip()\n",
    "                        value = parts[1].strip()\n",
    "\n",
    "\n",
    "                        if key==\"DATE/TIME SPECIMEN TAKEN\":\n",
    "                            check=True\n",
    "                            parsed_data[\"DATE/TIME SPECIMEN TAKEN\"] = value\n",
    "                            \n",
    "                 \n",
    "                        elif key==\"PATHOLOGIST\" or key==\"PATHOLOGIST/CYTOTECHNOLOGIST\" or key==\"SPECIMEN SUBMITTED BY\" or key==\"MICROBIOLOGY ACCESSION\":\n",
    "                            check=False\n",
    "                        else:\n",
    "                            if check:\n",
    "                                if key in columns:\n",
    "                                    parsed_data[key] = value\n",
    "                                elif key in exclude_labels:\n",
    "                                    continue\n",
    "                                else:\n",
    "                                    parsed_data[\"TEST_NAME\"] = key\n",
    "                                    parsed_data[\"TEST_RESULT\"] = value\n",
    "                                    data_list.append(parsed_data.copy())\n",
    "                                   \n",
    "                                \n",
    "    if data_list:\n",
    "            insert_data_batch(conn, data_list, columns,batch_size,start_date,end_date)\n",
    "            parsed_data = {}\n",
    "            data_list.clear()     \n",
    "            \n",
    "            \n",
    "\n",
    "def insert_data_batch(conn, data_list, columns,batch_size,start_date,end_date):\n",
    "#     start_date=pd.to_datetime(\"01/01/1900\")\n",
    "#     end_date=pd.to_datetime(\"06/10/2024\")\n",
    "    \"\"\"Insert data into the database in batches.\"\"\"\n",
    "    df= pd.DataFrame(data_list,columns=columns)\n",
    "    # Replace '@' with ' '\n",
    "    print(data_list)\n",
    "    df['DATE/TIME SPECIMEN TAKEN'] = df['DATE/TIME SPECIMEN TAKEN'].str.replace('@', ' ')\n",
    "    \n",
    "    # Replace '24:00' with '00:00' and add one day\n",
    "    mask_24 = df['DATE/TIME SPECIMEN TAKEN'].fillna('').str.contains(' 24:00')\n",
    "    df.loc[mask_24, 'DATE/TIME SPECIMEN TAKEN'] = df.loc[mask_24, 'DATE/TIME SPECIMEN TAKEN'].str.replace(' 24:00', ' 00:00')\n",
    "    df.loc[mask_24, 'DATE/TIME SPECIMEN TAKEN'] = pd.to_datetime(df.loc[mask_24, 'DATE/TIME SPECIMEN TAKEN'], format='%b %d, %Y %H:%M') + pd.DateOffset(days=1)\n",
    "\n",
    "    # Convert to datetime, handling different formats\n",
    "    df['DATE'] = pd.to_datetime(df['DATE/TIME SPECIMEN TAKEN'], format='%b %d, %Y %H:%M:%S', errors='coerce')\n",
    "    df['DATE'] = pd.to_datetime(df['DATE/TIME SPECIMEN TAKEN'], format='%b %d, %Y %H:%M', errors='coerce').fillna(df['DATE'])\n",
    "\n",
    "    # Update the original column with the converted dates\n",
    "    df['DATE/TIME SPECIMEN TAKEN'] = df['DATE']\n",
    "\n",
    "    # Drop the temporary 'DATE' column\n",
    "    df.drop(columns=['DATE'], inplace=True)\n",
    "\n",
    "    # Fill any remaining NaT values with a default value (e.g., NaN)\n",
    "    df['DATE/TIME SPECIMEN TAKEN'].fillna(pd.to_datetime(np.nan), inplace=True)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "        # Replace '@' with ' '\n",
    "    df['DATE REPORT COMPLETED'] = df['DATE REPORT COMPLETED'].str.replace('@', ' ')\n",
    "    \n",
    "    # Replace '24:00' with '00:00' and add one day\n",
    "    mask_24 = df['DATE REPORT COMPLETED'].fillna('').str.contains(' 24:00')\n",
    "    df.loc[mask_24, 'DATE REPORT COMPLETED'] = df.loc[mask_24, 'DATE REPORT COMPLETED'].str.replace(' 24:00', ' 00:00')\n",
    "    df.loc[mask_24, 'DATE REPORT COMPLETED'] = pd.to_datetime(df.loc[mask_24, 'DATE REPORT COMPLETED'], format='%b %d, %Y %H:%M') + pd.DateOffset(days=1)\n",
    "\n",
    "\n",
    "    # Convert to datetime, handling different formats\n",
    "    df['DATE'] = pd.to_datetime(df['DATE REPORT COMPLETED'], format='%b %d, %Y %H:%M:%S', errors='coerce')\n",
    "    df['DATE'] = pd.to_datetime(df['DATE REPORT COMPLETED'], format='%b %d, %Y %H:%M', errors='coerce').fillna(df['DATE'])\n",
    "\n",
    "    # Update the original column with the converted dates\n",
    "    df['DATE REPORT COMPLETED'] = df['DATE']\n",
    "\n",
    "    # Drop the temporary 'DATE' column\n",
    "    df.drop(columns=['DATE'], inplace=True)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    df['MRN'] = pd.to_numeric(df['MRN'],errors='coerce')\n",
    "    df['MRN'].fillna(0, inplace=True)\n",
    "    df['MRN'] = df['MRN'].astype(int)\n",
    "    \n",
    "    df['TEST_RESULT'] = df['TEST_RESULT'].apply(lambda x: x[:100])\n",
    "    df = df.where(pd.notnull(df), None)\n",
    "    df = df.replace({np.nan: None})\n",
    "    df=df.loc[(df['DATE REPORT COMPLETED']>start_date)&(df['DATE REPORT COMPLETED']<end_date)]\n",
    "    for col, max_length in string_columns_max_length.items():\n",
    "         df[col] = df[col].apply(lambda x: truncate_string(x, max_length))\n",
    "    if not df.empty:        \n",
    "        \n",
    "        data_list = [tuple(row) for row in df.to_numpy()]\n",
    "        cursor = conn.cursor()\n",
    "        cursor.fast_executemany = True\n",
    "        total_records = len(data_list)\n",
    "        num_batches = (total_records // batch_size) + 1\n",
    "        sql_insert = \"INSERT INTO LAB (MRN, [DATE/TIME SPECIMEN TAKEN], [DATE REPORT COMPLETED], [SPECIMEN TYPE], [REQUESTING LOCATION], [REQUESTING LOC/DIV], [TEST_NAME], [TEST_RESULT]) VALUES (?, ?, ?, ?, ?, ?, ?, ?)\"\n",
    "        for i in range(num_batches):\n",
    "            start_idx = i * batch_size\n",
    "            end_idx = min((i + 1) * batch_size, total_records)\n",
    "            batch_data = data_list[start_idx:end_idx]\n",
    "\n",
    "            cursor.executemany(sql_insert, batch_data)\n",
    "            conn.commit()\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "def main_function():\n",
    "        try:\n",
    "            extract_data()\n",
    "            conn = establish_connection()\n",
    "        except Exception as e:  \n",
    "            print(f\"Error encountered: {e}. Retrying in 1 minutes...\")\n",
    "            time.sleep(60)\n",
    "            main_function()\n",
    "#             if conn:\n",
    "        try:\n",
    "            'start parse file'\n",
    "            parse_file('output_labs.txt',conn)\n",
    "\n",
    "        except Exception as e:  \n",
    "            print(f\"Error encountered: {e}. Retrying in 1 minutes...\")\n",
    "            time.sleep(60)\n",
    "            main_function()\n",
    "#         finally:\n",
    "#             close_connection(conn)\n",
    "        print(\"The End\")\n",
    "        print(f\"Success! The next loop will start in 1 minutes...\")\n",
    "        time.sleep(60)\n",
    "        clear_output(wait=True)\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        try:\n",
    "            main_function()\n",
    "        except Exception as e:\n",
    "            print(f\"Error encountered: {e}. Retrying in 1 minutes...\")\n",
    "            main_function()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
